Some of the key bottlenecks in implementing the \gls{FMM} and \gls{KIFMM}, and potential
optimisation strategies in the computation of these algorithms, have already been
discussed. This chapter adds detail to the approaches used by \gls{PyExaFMM} to tackle
the issues raised. Namely, the approach to multiprocessing and caching the \gls{M2M},
\gls{L2L} and \gls{M2L} operators is discussed in Section \ref{sec:2_3_operator_caching}, and
the acceleration of the \gls{M2L} calculation via a low-rank approximation using the \gls{SVD}
is discussed in Section \ref{sec:2_4_svd_compression}. The other significant bottlenecks
and implementation issues addressed in thus in the implementation of \gls{PyExaFMM} are the
efficient construction of tree data structure (Section \ref{sec:2_2_efficient_trees}),
and the software design considerations (Section \ref{sec:2_5_software_design}).

The twin goals in designing \gls{PyExaFMM} were ensuring the extensibility and
testability of the software. Building easily extensible and testable numerical
codes is inherently challenging, the complexity of the algorithms and continuous
nature of their results making it hard to separate the logic from application
specific implementation details. As \gls{PyExaFMM} is implemented in Python, an
\textbf{\gls{interpreted}} and inherently \textbf{\gls{object-oriented-language}}, we are able to use some common and powerful
object oriented design principles to ensure extensibility. Concerns about the
overhead of using the object oriented design principles, in comparison to directly manipulating
primitives, such as those available in lower level compiled languages such as C
or C++, are misplaced for two reasons. Firstly, the implementation of Python objects
is syntactic sugar, methods and data for a given object are written into
a simple dictionary structure at run time, with the `class' syntax common to other
object oriented languages such as C++ or Java, offered for as they are familiar to
the programmer coming from such languages. Resultantly, all `primitives' such as
integers and strings in Python are actually objects by design, being quite different
in their construction from C or C++ where the programmer is given the power to
allocate memory for true primitives themselves. In Python the overhead therefore
comes from the interpreter, which transforms the source code into byte code which
is then compiled. This additional interpreter layer is the source of Pythonic overhead,
rather than the object abstraction in itself. Therefore, once the decision has
been made to use Python, there isn't a significant overhead from using object
oriented design principles, with the added benefit of increasing programmer
productivity, and increasing testability. Secondly, the vast Python ecosystem of
optimised libraries for numerical computation allow for the manipulation and
allocation of primitives in memory in a manner closer to a compiled language.
Specifically, \gls{PyExaFMM} implements all of its containers with NumPy, which
offers an interface for the allocation and access of numerical data with C-like
efficiency, due to the underlying subroutines being written in C. Additionally,
\gls{PyExaFMM} uses just-in-time (\textbf{\gls{JIT}}) via the Numba library on
numeric subroutines implemented with NumPy containers. Just-in-time compilation
refers to a system which analyses the byte-code of generated by an interpreter
for repetitive operations which would benefit from compilation and caching, therefore
combining the speed benefits of compiled languages, with the flexibility of interpreted
languages. Software design choices in light of the above analysis is considered
in detail in Section \ref{sec:2_5_software_design}, and the result of code
optimisation is benchmarked in Chapter \ref{chpt:3}, section \ref{sec:3_1_benchmarking},
alongside end-to-end testing of the entire algorithm implementation.

As with all optimised numeric codes, \gls{PyExaFMM} relies on an efficient
vectorised data structures, specifically an efficient representation of the tree
data structure used in the main \gls{FMM} loop. This is done via an Morton encoding,
which has the effect of translating multidimensional data to one dimension whilst
preserving the data's locality. This allows for an efficient vector representation
of box center's in a tree, and for the application of optimised numeric libraries.
The software implementation is discussed in detail in Section \ref{sec:2_2_efficient_trees}.
