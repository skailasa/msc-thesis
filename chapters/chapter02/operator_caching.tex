Practical implementations of the \gls{KIFMM} rely on the creation of efficient
surfaces used in the calculation of kernel matrices, as well as a stable method for
computing the inverse of these kernel matrices. The former problem naturally leads
to the implementation of caching code to cache, re-use, and scale operator matrices
as appropriate. Whereas the latter requires the implementation of a stable method to
solve the system of linear equations for each \gls{KIFMM} operator. As mentioned
in Chapter \ref{chpt:1_introduction}, Section \ref{sec:1_2_kifmm_overview}, \gls{PyExaFMM} uses
a pseudoinverse computed via an SVD to solve this linear system. This section
provides the implementation details used to address both of these issues.

\gls{PyExaFMM} uses cubic surfaces for all check and equivalent surfaces discretised
to the same degree, this follows the precedent set by the original authors \cite{Ying:2004:JCP}, and
allows for the application of simple quadrature rules to calculate the various
operator integrals such as those in equations (\ref{eq:1_2_m2m}), (\ref{eq:1_2_m2l})
and (\ref{eq:1_2_l2l}). In fact, as the number of quadrature points is generally
chosen to be relatively low \gls{PyExaFMM} uses a direct computation to
compute the required integrals. Specifically, an order $p$ expansion results in,

\begin{equation}
    n_q =  6(p-1)^2 + 2
    \label{eq:2_2_quadrature_points}
\end{equation}

where $n_q$ is the number of quadrature points on a given surface. This equation can be
justified from the enforcement of the fact $p$ quadrature points are placed on the corners
of the cube, as well as being placed evenly along each edge of the cube. Similarly the
interior of each face of the cube is discretised to have quadrature points that form
a uniform Cartesian grid with the points at the edges and corners. Therefore,
by over-counting the nodes on the edge the 6 sides of the cube lead to $6p^2$ quadrature
points, however each corner point is over-counted three times, and the quadrature points
in the interior of a edge are over-counted twice. This leads to $6p^2 - 12(p-2) - 16$,
which is equivalent to (\ref{eq:2_2_quadrature_points}), however computed with more operations.
Therefore even for an order $p=9$ expansion, which can be employed to compute
potentials to 9 digits of accuracy with respect to a direct computation
\cite{Malhotra:2015:CCP}, there are just 386 quadrature points on a given check
or equivalent surface.

The operators associated with the \gls{KIFMM}, described by equations
(\ref{eq:1_2_m2m}), (\ref{eq:1_2_m2l}) and (\ref{eq:1_2_l2l}) are of the general
form,

\begin{equation}
    K_A\phi^A = K_B\phi^B
\end{equation}

where $K_A$ and $K_B$ are integral operators describing the action of the kernel
between two surfaces describing their given box, and can be discretised into
matrices by performing numerical quadrature but storing the element-wise results
as matrix elements; and $\phi^A$ and $\phi^B$ are equivalent densities, one of
which is generally unknown and sought. This can be reformulated as,

\begin{equation}
    \phi^A = (K_A)^{-1}K_B\phi^B
    \label{eq:2_3_general_operator}
\end{equation}

in the case $\phi^B$ is known and $\phi^A$ is sought. For the remainder of this
thesis, the quantity $(K_A)^{-1}K_B$ will be referred to as an \textbf{\gls{operator-matrix}},
for example the `M2L operator matrix', and so forth. This is a useful quantity
to cache, in comparison to just storing the inverse and the kernel matrices separately,
as we can just apply the M2L operator matrix to the known source density in order
to calculate the unknown source density in a single matrix-vector product.

As described in Chapter \ref{chpt:1_introduction}, Section \ref{sec:1_2_kifmm_overview}, one
can take advantage of the similarities between the nature of the calculation of
(\ref{eq:2_3_general_operator}) for the \gls{M2M} and \gls{L2L} operator matrices, if
the check and equivalent surfaces in both cases are chosen correctly. Specifically,
if the upward check surface is chosen to coincide with the downward equivalent
surface, and the upward equivalent surface is chosen to coincide with the
downward check surface, the matrix $K_A$ in for both cases are the transpose of
of one another, with the addition of a scaling factor to account for the fact
that $K_A$ describes the surfaces at the child level for a the \gls{L2L} operation,
versus at the parent level for the \gls{M2M} operation. Furthermore as each of these
operations is only relative between a parent box and its respective children, one
can just compute all M2L and L2L operator matrices for a given parent and its
respective children and re-use at any level of an octree. \gls{PyExaFMM} therefore
computes, and caches, the M2M and L2L operators and saves them alongside the
corresponding child Morton \gls{key} of the child box involved in their calcualtion,
 this can be looked up as needed during the \gls{KIFMM} main loop. For the M2L
 matrices, an alternative approach is taken, \gls{PyExaFMM} computes
and caches all M2L operator matrices for all source boxes in a given target box's
interaction list for all in all target boxes
interaction list at all levels. Presently, this computation is distributed across
the available processors of multicore machine
with Python's native multiprocessing utilities. However, dense matrix-vector
product operations, such as those required to find the \gls{M2L} operator
matrices, are good candidates for offloading to \gls{GPU}s. Modern \gls{GPU}s
consist of up to $O(10^3)$ processor cores at the higher end,
in comparison to $O(10)$ on an average desktop work work station's CPU
\cite{Hwu:2011:MKP}. Roughly speaking, this number of cores allows for massive task level parallelism,
and works especially well for single-instruction multiple-data (\gls{SIMD}) type tasks, in which
a single instruction is passed to each process alongside a small amount of data on which it
is required to operate. A dense matrix vector product is therefore an ideal
candidate for GPU acceleration, due to the independence of the calculation between each row
of the matrix and the vector, each of which can be broken up again into independent element-wise
products. As there are up to 189 M2L operator matrices for a given
target box, corresponding to the potential length of a target box's interaction
list in three dimensions \cite{Ying:2004:JCP}, this problem can be reformulated
as a linear system involving the matrix vector products of M2L matrix operators
with their respective source equivalent densities,

\begin{equation}
    \left [ A_1 | A_2 | ... | A_I \right] \begin{bmatrix} \phi_1 \\ \phi_2 \\  ... \\  \phi_I \end{bmatrix} = \begin{bmatrix} q_1\\ q_2\\  ... \\  q_I \end{bmatrix}
\end{equation}

where $\{A_i | i \in [1, 2, ..., I]\}$, are the M2L operator matrices and $I$ is the size of a given
target box's interaction list. Additionally, $\{\phi_i | i \in [1,2, ..., I]\}$ and $\{q_i | i \in [1,2, ..., I]\}$
are the source box's equivalent density and the corresponding check potential vectors
respectively. The concatenated operator matrix for this system can be compressed, and still
provide accurate results. This is the focus of Section \ref{sec:2_4_svd_compression},
where it's shown how \gls{PyExaFMM} uses a low-rank estimate of this matrix using
an \gls{SVD}. This compression has the potential to offer a large saving in terms
of the size of the cached M2L operator, and the time complexity of its application
on source densities. Therefore, the decision to compute the \gls{M2L} operators for
all target boxes is taken with the potential for future GPU acceleration and
compression techniques in mind.

The values chosen for the size of the for the size of the upward/downward
check and equivalent matrices are taken with reference to \cite{Malhotra:2015:CCP},
as the authors empirically found find them to achieve good results. Specifically,
the radius\footnote{It's conventional in FMM literature to refer to the half-side
length of a box as the `radius'}, of the upward check surface and downward equivalent
surface of a given is set to be 2.95 times the radius of the box, and the radius of
upward equivalent surface and downward check surface are set to be 1.05 times the radius
of the given box. This parameter choice is common to both major C++ implementations of
of the \gls{KIFMM} \cite{exafmm,Malhotra:2015:CCP}.

As mentioned, the required operator matrices are loaded from disk at run-time, ready to
be used by \gls{PyExaFMM}. Currently, objects corresponding to cached \gls{M2L}
matrices are simple serialised to be loaded in their entirety at run time by
\gls{PyExaFMM}. However, the translation of the cache to HDF5 based storage is
an area of future extension for \gls{PyExaFMM}, and has been implemented
for the storage of the \gls{M2M} and \gls{L2L} operator matrices. HDF5 offers an
interface for loading slices of large datasets that may be stored on disks, allowing
for rapid read times for subsets of a data, even if the underlying dataset
is of the order of gigabytes \cite{Wasser:NSF}. Furthermore, HDF5 allows for the
hierarchical storage of numeric arrays, this amounts to creating
a database like structure on disk which can store numeric arrays of different
dimensions.

The  benchmark figures for the potential speedup offered by the above optimisations
implemented in \gls{PyExaFMM}, namely multiprocessing for the \gls{M2L} operators
and the usage of HDF5 vs object serialisation for large datasets are given
in Chapter \ref{chpt:3}, Section \ref{sec:3_1_benchmarking}.

As discussed in Chapter \ref{chpt:1_introduction}, Section \ref{sec:1_2_kifmm_overview},
the calculation of (\ref{eq:2_3_general_operator}) is ill-conditioned, therefore
\gls{PyExaFMM} uses a Tikhonov regularisation scheme in combination with an SVD
to to calculate the inverse of the operator matrices, which is adapted from the
implementation of ExaFMM-T and PVFMM \cite{Malhotra:2015:CCP, exafmm}.

Consider the SVD of a given operator matrix,

\begin{equation}
    K_A = U \Sigma V^*
\end{equation}

with a pseudoinverse of

\begin{equation}
    K_A^\dagger = V \Sigma^{-1} U^*
\end{equation}

the inversion of the diagonal matrix of singular values can be regularised as,

\begin{equation}
    \Sigma^{-1} = \underbrace{(\alpha I + \Sigma^*\Sigma)^{-1}}_{\Sigma_{\text{reg}}}
    \label{eq:2_4_regularised_general_operator}
\end{equation}

a pseudoinverse using an \gls{SVD} is then calculated for this matrix, in which
singular vectors corresponding to `small' singular values less than a specified
tolerance are filtered out of the final approximation in order to maintain
numerical stability. This tolerance value is in practice set to be a number close
to machine precision, and \gls{PyExaFMM} uses a value of $\text{tol} = 4 \cdot \text{EPS} \cdot \max (\Sigma_{\text{reg}})$,
where EPS is machine precision, and $\max (\Sigma_{\text{reg}})$ is the largest
entry in $\Sigma_{\text{reg}}$. This has been determined empirically to provide
stable results. The regularisation parameter $\alpha$ is also determined empirically,
and a value proportional to the largest singular value of $K_A$, where
$\alpha=0.075 \cdot \max(\Sigma)$ is found to provide stable results.\footnote{
    The regularisation parameter $\alpha$ used by the authors of \cite{Malhotra:2015:CCP}
    is $\alpha \approx  1 \times 10^{-9}$, which was provided through direct email correspondence. However,
    they note that this is an empirical value, reflecting the expansion order of
    the surfaces they used in their simulations.
}

