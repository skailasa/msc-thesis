Building easily extensible and testable numerical codes is inherently challenging,
the complexity of the algorithms and continuous nature of their results making it hard to separate the logic from application
specific implementation details. As \gls{PyExaFMM} is implemented in Python, an
\gls{interpreted} and inherently \gls{object-oriented-language}, we are able to use some common and powerful
object oriented design principles to ensure extensibility.

Concerns about the overhead of using the object oriented design principles, in comparison to directly manipulating
primitives, such as those available in lower level compiled languages such as C
or C++, are misplaced for two reasons. Firstly, the implementation of Python objects
is syntactic sugar, methods and data for a given object are written into
a simple dictionary structure at run time, with the `class' syntax common to other
object oriented languages such as C++ or Java, offered as they are familiar to
the programmer coming from such languages. Resultantly, all `primitives' such as
integers and strings in Python are actually objects by design, being quite different
in their construction from C or C++ where the programmer is given the power to
allocate memory for true primitives themselves. In Python the overhead therefore
comes from the interpreter, which transforms the source code into byte code which
is then compiled. This additional interpreter layer is the source of Pythonic overhead,
rather than the object abstraction in itself. Therefore, once the decision has
been made to use Python, there isn't a significant overhead from using object
oriented design principles, with the added benefit of increasing programmer
productivity, and increasing testability \cite{Ramalho:2015:Oreilly}.

Secondly, the vast Python ecosystem of optimised libraries for numerical
computation allow for the manipulation and
allocation of primitives in memory in a manner closer to a compiled language.
Specifically, \gls{PyExaFMM} implements all of its containers with NumPy, which
offers an interface for the allocation and access of numerical data with C-like
efficiency, due to the underlying subroutines being written in C. Additionally,
\gls{PyExaFMM} uses just-in-time (\gls{JIT}) via the Numba library on
numeric subroutines implemented with NumPy containers. Just-in-time compilation
refers to a system which analyses the byte-code of generated by an interpreter
for repetitive operations which would benefit from compilation and caching, therefore
combining the speed benefits of compiled languages, with the flexibility of interpreted
languages.

However, the requirement for performance for numerical
codes requires objects to be simple enough, without layers of abstraction, in
order to access logic and data access functionality for optimisation purposes.

Though benchmarked in terms of it's performance

- Comment on how this results in requirements for a few simple objects.

- Dependency injection
    - data, config file

- Separation of Concerns

   - separation of logic from optimisation, operator caching,
       tree construction.

    - strategy pattern usage for kernels.

- UML diagram for strategy pattern,
- UML diagram for dependency injection

- Comment on how unit testing is not enough for numerical codes
    - requirement for integration tests and how they're underdeveloped in
    the current code.

